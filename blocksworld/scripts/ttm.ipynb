{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BlocksWorld TTM\n",
    "\n",
    "Use the **2nd Encoding** format to use the TTM Granite model on the BlocksWorld domain.\n",
    "\n",
    "Key modifications from standard TTM:\n",
    "\n",
    "- Input format includes goal state concatenated with current state\n",
    "- Binary state prediction instead of continuous values\n",
    "- Custom metrics for planning success\n",
    "- Sequence padding to handle variable-length plans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Optional, Dict, Any\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments, set_seed\n",
    "\n",
    "from tsfm_public import TrackingCallback\n",
    "from tsfm_public.toolkit.get_model import get_model\n",
    "\n",
    "from BlocksWorld import BlocksWorldGenerator\n",
    "from pprint import pformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: [13, 'ibm-granite/granite-timeseries-ttm-r2', 360, device(type='mps')]\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "SEED = 13\n",
    "set_seed(SEED)\n",
    "TTM_MODEL_PATH = \"ibm-granite/granite-timeseries-ttm-r2\"\n",
    "\n",
    "# Supported CLs are 52, 90, 180, 360, 520, 1024, 1536\n",
    "CONTEXT_LENGTH = 360\n",
    "\n",
    "# Determine device\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using: {pformat([SEED, TTM_MODEL_PATH, CONTEXT_LENGTH, DEVICE])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan Dataclass\n",
    "\n",
    "For storing individual planning examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    context_length: int = CONTEXT_LENGTH\n",
    "    prediction_length: int = 96\n",
    "    learning_rate: float = 1e-4\n",
    "    batch_size: int = 32\n",
    "    num_epochs: int = 50\n",
    "    state_dim: Optional[int] = None  # Will be set during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BlocksWorldSample:\n",
    "    initial_state: List[int]\n",
    "    goal_state: List[int]\n",
    "    plan: List[List[int]]\n",
    "    actions: List[List[str]]\n",
    "    feature_names: List[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom BlocksWorld Dataset Class\n",
    "\n",
    "The class handles:\n",
    "\n",
    "- Loading JSON plan data\n",
    "- Padding sequences to match context length\n",
    "- Combining state and goal information\n",
    "- Converting to appropriate tensor format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlocksWorldDataset(Dataset):\n",
    "    def __init__(self, data_path: str, context_length: int, prediction_length: int):\n",
    "        self.context_length: int = context_length\n",
    "        self.prediction_length: int = prediction_length\n",
    "        self.device = DEVICE\n",
    "\n",
    "        with open(data_path, \"r\") as f:\n",
    "            raw_data = json.load(f)[\"plans\"]\n",
    "\n",
    "        self.samples: List[BlocksWorldSample] = []\n",
    "        for item in raw_data:\n",
    "            sample = BlocksWorldSample(\n",
    "                initial_state=item[\"initial_state\"],\n",
    "                goal_state=item[\"goal_state\"],\n",
    "                plan=item[\"plan\"],\n",
    "                actions=item[\"actions\"],\n",
    "                feature_names=item[\"feature_names\"],\n",
    "            )\n",
    "            self.samples.append(sample)\n",
    "\n",
    "        # Get dimensionality from first sample\n",
    "        self.state_dim: int = len(self.samples[0].initial_state)\n",
    "\n",
    "    def __len__(self):  # Length of the Dataset\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "\n",
    "        # Pad plan sequence to match context_length + prediction_length\n",
    "        plan_len = len(sample.plan)\n",
    "        full_seq = sample.plan + [sample.goal_state] * (\n",
    "            self.context_length + self.prediction_length - plan_len\n",
    "        )\n",
    "\n",
    "        # Split into past and future\n",
    "        past_seq = full_seq[: self.context_length]\n",
    "        future_seq = full_seq[self.context_length : self.context_length + self.prediction_length]\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        past_values = np.array(past_seq, dtype=np.float32)\n",
    "        future_values = np.array(future_seq, dtype=np.float32)\n",
    "\n",
    "        # Create masks (1 indicates valid values)\n",
    "        past_observed_mask = np.ones((self.context_length, self.state_dim), dtype=np.float32)\n",
    "        future_observed_mask = np.ones((self.prediction_length, self.state_dim), dtype=np.float32)\n",
    "\n",
    "        # Include goal state as static categorical feature\n",
    "        static_categorical_values = np.array(sample.goal_state, dtype=np.float32)\n",
    "\n",
    "        return {\n",
    "            \"past_values\": torch.tensor(past_values, dtype=torch.float32).to(self.device),\n",
    "            \"future_values\": torch.tensor(future_values, dtype=torch.float32).to(self.device),\n",
    "            \"past_observed_mask\": torch.tensor(past_observed_mask, dtype=torch.float32).to(\n",
    "                self.device\n",
    "            ),\n",
    "            \"future_observed_mask\": torch.tensor(future_observed_mask, dtype=torch.float32).to(\n",
    "                self.device\n",
    "            ),\n",
    "            \"static_categorical_values\": torch.tensor(\n",
    "                static_categorical_values, dtype=torch.float32\n",
    "            ).to(self.device),\n",
    "            \"freq_token\": torch.zeros(1, dtype=torch.long).to(self.device),  # Placeholder for TTM\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why we need padding?**\n",
    "The model expects every input sequence to be exactly `context_length` timesteps long, but our planning sequences can vary in length (some plans take 3 steps, others might take 10). So, the padding strategy is, (1) when plan is too short, pad with the goal state or (2) when plan is too long, truncate to context_length.\n",
    "\n",
    "For example, if we have:\n",
    "\n",
    "```python\n",
    "context_length = 5\n",
    "plan = [[1,0,0], [1,1,0], [0,1,1]]  # 3 steps\n",
    "goal_state = [0,1,1]\n",
    "```\n",
    "\n",
    "After padding:\n",
    "\n",
    "```python\n",
    "padded_plan = [\n",
    "    [1,0,0],    # Original step 1\n",
    "    [1,1,0],    # Original step 2\n",
    "    [0,1,1],    # Original step 3\n",
    "    [0,1,1],    # Padded with goal\n",
    "    [0,1,1]     # Padded with goal\n",
    "]\n",
    "```\n",
    "\n",
    "Why pad with goal state instead of zeros?:\n",
    "\n",
    "1. **Semantic Meaning**: Using the goal state maintains the logical meaning - \"after reaching the goal, we stay in the goal state\"\n",
    "2. **Learning Signal**: It helps the model understand that reaching the goal is a stable state\n",
    "3. **Consistency**: Ensures all states in the sequence are valid block configurations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BlocksWorld-Based TTM Class\n",
    "\n",
    "To handle training and prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlocksWorldTTM:\n",
    "    def __init__(\n",
    "        self,\n",
    "        context_length: int = CONTEXT_LENGTH,\n",
    "        prediction_length: int = 96,\n",
    "        learning_rate: float = 1e-4,\n",
    "        batch_size: int = 32,\n",
    "        num_epochs: int = 50,\n",
    "    ):\n",
    "        self.config = ModelConfig(\n",
    "            context_length=context_length,\n",
    "            prediction_length=prediction_length,\n",
    "            learning_rate=learning_rate,\n",
    "            batch_size=batch_size,\n",
    "            num_epochs=num_epochs,\n",
    "        )\n",
    "        self.device = DEVICE\n",
    "        self.model = None\n",
    "        self.trainer = None\n",
    "\n",
    "    def train(self, train_dataset: Dataset, val_dataset: Optional[Dataset] = None):\n",
    "        \"\"\"Train the model on given datasets\"\"\"\n",
    "        # Store state dimension from training data\n",
    "        self.config.state_dim = (\n",
    "            train_dataset.dataset.state_dim\n",
    "            if hasattr(train_dataset, \"dataset\")\n",
    "            else train_dataset.state_dim\n",
    "        )\n",
    "\n",
    "        # Initialize model\n",
    "        self.model = get_model(\n",
    "            TTM_MODEL_PATH,\n",
    "            context_length=self.config.context_length,\n",
    "            prediction_length=self.config.prediction_length,\n",
    "            head_dropout=0.1,\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Training arguments\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=\"blocks_world_ttm\",\n",
    "            learning_rate=self.config.learning_rate,\n",
    "            num_train_epochs=self.config.num_epochs,\n",
    "            per_device_train_batch_size=self.config.batch_size,\n",
    "            per_device_eval_batch_size=self.config.batch_size,\n",
    "            eval_strategy=\"epoch\" if val_dataset else \"no\",\n",
    "            save_strategy=\"epoch\",\n",
    "            load_best_model_at_end=True if val_dataset else False,\n",
    "            metric_for_best_model=\"eval_loss\",\n",
    "            greater_is_better=False,\n",
    "            seed=SEED,\n",
    "            report_to=\"none\",\n",
    "            dataloader_pin_memory=False,\n",
    "        )\n",
    "\n",
    "        # Callbacks\n",
    "        callbacks = [\n",
    "            TrackingCallback(),\n",
    "            EarlyStoppingCallback(early_stopping_patience=5),\n",
    "        ]\n",
    "\n",
    "        # Optimizer and scheduler\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.config.learning_rate)\n",
    "        scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=self.config.learning_rate,\n",
    "            epochs=self.config.num_epochs,\n",
    "            steps_per_epoch=math.ceil(len(train_dataset) / self.config.batch_size),\n",
    "        )\n",
    "\n",
    "        # Initialize trainer\n",
    "        self.trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "            callbacks=callbacks,\n",
    "            optimizers=(optimizer, scheduler),\n",
    "        )\n",
    "\n",
    "        # Train\n",
    "        self.trainer.train()\n",
    "\n",
    "    def predict(self, initial_states: torch.Tensor, goal_states: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Generate action sequences to reach goals from given states\"\"\"\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model needs to be trained or loaded before prediction\")\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            batch_size = initial_states.shape[0]\n",
    "\n",
    "            # Create context sequence by repeating initial states\n",
    "            context_sequence = initial_states.unsqueeze(1).repeat(1, self.config.context_length, 1)\n",
    "\n",
    "            # Prepare inputs\n",
    "            inputs = {\n",
    "                \"past_values\": context_sequence.to(self.device),\n",
    "                \"past_observed_mask\": torch.ones_like(context_sequence).to(self.device),\n",
    "                \"static_categorical_values\": goal_states.to(self.device),\n",
    "                \"freq_token\": torch.zeros(batch_size, dtype=torch.long).to(self.device),\n",
    "            }\n",
    "\n",
    "            # Generate predictions\n",
    "            outputs = self.model(**inputs)\n",
    "            predictions = torch.sigmoid(outputs[0])\n",
    "            predictions = torch.round(predictions)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def save(self, path: str):\n",
    "        \"\"\"Save model weights and configuration\"\"\"\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"No model to save. Train or load a model first.\")\n",
    "\n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "        # Save model state\n",
    "        model_path = os.path.join(path, \"model.pt\")\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "\n",
    "        # Save configuration\n",
    "        config_path = os.path.join(path, \"config.json\")\n",
    "        with open(config_path, \"w\") as f:\n",
    "            json.dump(asdict(self.config), f)\n",
    "\n",
    "        print(f\"Model saved to {path}\")\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path: str) -> \"BlocksWorldTTM\":\n",
    "        \"\"\"Load model weights and configuration\"\"\"\n",
    "        # Load configuration\n",
    "        config_path = os.path.join(path, \"config.json\")\n",
    "        with open(config_path, \"r\") as f:\n",
    "            config_dict = json.load(f)\n",
    "\n",
    "        # Create instance with loaded config\n",
    "        instance = cls(\n",
    "            context_length=config_dict[\"context_length\"],\n",
    "            prediction_length=config_dict[\"prediction_length\"],\n",
    "            learning_rate=config_dict[\"learning_rate\"],\n",
    "            batch_size=config_dict[\"batch_size\"],\n",
    "            num_epochs=config_dict[\"num_epochs\"],\n",
    "        )\n",
    "        instance.config.state_dim = config_dict[\"state_dim\"]\n",
    "\n",
    "        # Initialize and load model\n",
    "        instance.model = get_model(\n",
    "            TTM_MODEL_PATH,\n",
    "            context_length=instance.config.context_length,\n",
    "            prediction_length=instance.config.prediction_length,\n",
    "            head_dropout=0.1,\n",
    "        ).to(instance.device)\n",
    "\n",
    "        model_path = os.path.join(path, \"model.pt\")\n",
    "        instance.model.load_state_dict(torch.load(model_path, map_location=instance.device))\n",
    "        instance.model.eval()\n",
    "\n",
    "        print(f\"Model loaded from {path}\")\n",
    "        return instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model receives these key components for each sample during **training**:\n",
    "\n",
    "1. Past Values (past_values):\n",
    "\n",
    "   `past_values = torch.tensor(past_seq, dtype=torch.float32)`\n",
    "\n",
    "   - Shape: [batch_size, context_length, state_dim]\n",
    "   - These are sequences of states leading up to the current point\n",
    "   - Each state is a binary vector representing the blocks world predicates\n",
    "   - Length is padded to context_length (`CONTEXT_LENGTH` by default)\n",
    "\n",
    "2. Future Values (future_values):\n",
    "\n",
    "   `future_values = torch.tensor(future_seq, dtype=torch.float32)`\n",
    "\n",
    "   - Shape: [batch_size, prediction_length, state_dim]`\n",
    "   - These are the target sequences of states we want to predict\n",
    "   - Length is padded to prediction_length (96 by default)\n",
    "\n",
    "3. Observation Masks:\n",
    "\n",
    "   `past_observed_mask = torch.ones((context_length, state_dim))`\n",
    "\n",
    "   `future_observed_mask = torch.ones((prediction_length, state_dim))`\n",
    "\n",
    "   - Binary masks indicating which values are valid (1) vs padding (0)\n",
    "   - Helps model ignore padded values during training\n",
    "\n",
    "4. Static Categorical Values:\n",
    "\n",
    "   `static_categorical_values = torch.tensor(sample.goal_state)`\n",
    "\n",
    "   - Shape: [batch_size, state_dim]\n",
    "   - The goal state we want to reach\n",
    "   - Stays constant across the entire sequence\n",
    "   - Helps guide the prediction towards the goal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During Prediction the model takes:\n",
    "\n",
    "1. Initial States:\n",
    "\n",
    "   `past_values = torch.tensor(initial_states).unsqueeze(1).repeat(1, context_length, 1)`\n",
    "\n",
    "   - The starting state is repeated to fill the context window\n",
    "   - This gives the model the current state as context\n",
    "\n",
    "2. Goal States:\n",
    "\n",
    "   `static_categorical_values = torch.tensor(goal_states)`\n",
    "\n",
    "   - Target goal state as static features\n",
    "   - Guides the generation of the plan\n",
    "\n",
    "The model outputs:\n",
    "\n",
    "```\n",
    "predictions = torch.sigmoid(outputs[0])  # Convert to probabilities\n",
    "predictions = torch.round(predictions)   # Convert to binary states\n",
    "```\n",
    "\n",
    "- Shape: [batch_size, prediction_length, state_dim]\n",
    "- Sequence of predicted states forming a plan\n",
    "- Each state is a binary vector matching the input encoding\n",
    "- The sequence should transition from initial state to goal state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(data_path: str, context_length: int, prediction_length: int):\n",
    "    \"\"\"Create train/val/test datasets\"\"\"\n",
    "    full_dataset = BlocksWorldDataset(data_path, context_length, prediction_length)\n",
    "\n",
    "    # Split indices\n",
    "    total_size = len(full_dataset)\n",
    "    train_size = int(0.7 * total_size)\n",
    "    val_size = int(0.15 * total_size)\n",
    "    test_size = total_size - train_size - val_size\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "        full_dataset,\n",
    "        [train_size, val_size, test_size],\n",
    "        generator=torch.Generator().manual_seed(SEED),\n",
    "    )\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(predictions, targets):\n",
    "    \"\"\"Compute metrics for predicted plans\"\"\"\n",
    "    predictions = predictions.numpy()\n",
    "    targets = targets.numpy()\n",
    "\n",
    "    # State prediction accuracy\n",
    "    state_accuracy = np.mean(predictions == targets)\n",
    "\n",
    "    # Goal achievement rate (exact match of final state)\n",
    "    goal_achieved = np.all(predictions[:, -1] == targets[:, -1], axis=1)\n",
    "    goal_achievement_rate = np.mean(goal_achieved)\n",
    "\n",
    "    # Partial goal achievement (percentage of correct final state bits)\n",
    "    partial_goal = np.mean(predictions[:, -1] == targets[:, -1], axis=1)\n",
    "    avg_partial_goal = np.mean(partial_goal)\n",
    "\n",
    "    return {\n",
    "        \"state_accuracy\": state_accuracy,\n",
    "        \"goal_achievement_rate\": goal_achievement_rate,\n",
    "        \"avg_partial_goal\": avg_partial_goal,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_dataset, verbose=True):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation of the model with more detailed metrics\n",
    "    \"\"\"\n",
    "    model.model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    goal_state_predictions = []\n",
    "    goal_state_targets = []\n",
    "\n",
    "    num_samples = len(test_dataset)\n",
    "    num_exact_matches = 0\n",
    "    num_partial_matches = 0\n",
    "    total_bits_correct = 0\n",
    "    total_bits = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            sample = test_dataset[i]\n",
    "\n",
    "            # Get initial and goal states\n",
    "            initial_state = sample[\"past_values\"][0]\n",
    "            goal_state = sample[\"static_categorical_values\"]\n",
    "            target = sample[\"future_values\"]\n",
    "\n",
    "            # Create context sequence\n",
    "            context_sequence = initial_state.unsqueeze(0).repeat(1, model.config.context_length, 1)\n",
    "\n",
    "            # Prepare inputs\n",
    "            inputs = {\n",
    "                \"past_values\": context_sequence.to(model.device),\n",
    "                \"past_observed_mask\": torch.ones_like(context_sequence).to(model.device),\n",
    "                \"static_categorical_values\": goal_state.unsqueeze(0).to(model.device),\n",
    "                \"freq_token\": torch.zeros(1, dtype=torch.long).to(model.device),\n",
    "            }\n",
    "\n",
    "            # Get prediction\n",
    "            outputs = model.model(**inputs)\n",
    "            prediction = torch.sigmoid(outputs[0])\n",
    "            prediction = torch.round(prediction)\n",
    "\n",
    "            # Store predictions and targets\n",
    "            all_predictions.append(prediction)\n",
    "            all_targets.append(target)\n",
    "\n",
    "            # Focus on goal states (final states)\n",
    "            pred_goal = prediction[0, -1]\n",
    "            true_goal = target[-1]\n",
    "\n",
    "            goal_state_predictions.append(pred_goal)\n",
    "            goal_state_targets.append(true_goal)\n",
    "\n",
    "            # Calculate exact matches\n",
    "            if torch.all(pred_goal == true_goal):\n",
    "                num_exact_matches += 1\n",
    "\n",
    "            # Calculate partial matches (more than 50% bits correct)\n",
    "            num_correct_bits = torch.sum(pred_goal == true_goal).item()\n",
    "            total_bits_correct += num_correct_bits\n",
    "            total_bits += len(pred_goal)\n",
    "\n",
    "            if num_correct_bits > len(pred_goal) / 2:\n",
    "                num_partial_matches += 1\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        \"num_samples\": num_samples,\n",
    "        \"num_exact_matches\": num_exact_matches,\n",
    "        \"exact_match_rate\": num_exact_matches / num_samples,\n",
    "        \"num_partial_matches\": num_partial_matches,\n",
    "        \"partial_match_rate\": num_partial_matches / num_samples,\n",
    "        \"bit_accuracy\": total_bits_correct / total_bits,\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nDetailed Model Evaluation Metrics:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Total number of test samples: {metrics['num_samples']}\")\n",
    "        print(f\"Number of exact goal state matches: {metrics['num_exact_matches']}\")\n",
    "        print(f\"Exact match rate: {metrics['exact_match_rate']:.4f}\")\n",
    "        print(f\"Number of partial matches (>50% correct): {metrics['num_partial_matches']}\")\n",
    "        print(f\"Partial match rate: {metrics['partial_match_rate']:.4f}\")\n",
    "        print(f\"Bit-level accuracy: {metrics['bit_accuracy']:.4f}\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def analyze_error_patterns(model, test_dataset, verbose=True):\n",
    "    \"\"\"\n",
    "    Enhanced error pattern analysis with more detailed statistics\n",
    "    \"\"\"\n",
    "    model.model.eval()\n",
    "    successes = []\n",
    "    failures = []\n",
    "\n",
    "    bit_error_counts = {}  # Track which bits are most commonly wrong\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(test_dataset)):\n",
    "            sample = test_dataset[i]\n",
    "\n",
    "            # Get initial and goal states\n",
    "            initial_state = sample[\"past_values\"][0]\n",
    "            goal_state = sample[\"static_categorical_values\"]\n",
    "            target = sample[\"future_values\"][-1]\n",
    "\n",
    "            # Create context sequence\n",
    "            context_sequence = initial_state.unsqueeze(0).repeat(1, model.config.context_length, 1)\n",
    "\n",
    "            # Prepare inputs\n",
    "            inputs = {\n",
    "                \"past_values\": context_sequence.to(model.device),\n",
    "                \"past_observed_mask\": torch.ones_like(context_sequence).to(model.device),\n",
    "                \"static_categorical_values\": goal_state.unsqueeze(0).to(model.device),\n",
    "                \"freq_token\": torch.zeros(1, dtype=torch.long).to(model.device),\n",
    "            }\n",
    "\n",
    "            # Get prediction\n",
    "            outputs = model.model(**inputs)\n",
    "            prediction = torch.sigmoid(outputs[0])\n",
    "            prediction = torch.round(prediction)\n",
    "            predicted_goal = prediction[0, -1]\n",
    "\n",
    "            # Calculate error statistics\n",
    "            errors = (predicted_goal != target).nonzero().squeeze(1)\n",
    "            num_errors = len(errors)\n",
    "\n",
    "            # Track which bits had errors\n",
    "            for error_idx in errors:\n",
    "                if error_idx.item() not in bit_error_counts:\n",
    "                    bit_error_counts[error_idx.item()] = 0\n",
    "                bit_error_counts[error_idx.item()] += 1\n",
    "\n",
    "            case = {\n",
    "                \"initial_state\": initial_state.cpu().numpy(),\n",
    "                \"goal_state\": goal_state.cpu().numpy(),\n",
    "                \"predicted_goal\": predicted_goal.cpu().numpy(),\n",
    "                \"target_goal\": target.cpu().numpy(),\n",
    "                \"num_errors\": num_errors,\n",
    "                \"error_positions\": errors.cpu().numpy(),\n",
    "            }\n",
    "\n",
    "            if num_errors == 0:\n",
    "                successes.append(case)\n",
    "            else:\n",
    "                failures.append(case)\n",
    "\n",
    "    analysis = {\n",
    "        \"num_successes\": len(successes),\n",
    "        \"num_failures\": len(failures),\n",
    "        \"success_rate\": len(successes) / (len(successes) + len(failures)),\n",
    "        \"bit_error_counts\": bit_error_counts,\n",
    "        \"successes\": successes,\n",
    "        \"failures\": failures,\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nError Pattern Analysis:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Number of successful predictions: {analysis['num_successes']}\")\n",
    "        print(f\"Number of failed predictions: {analysis['num_failures']}\")\n",
    "        print(f\"Success rate: {analysis['success_rate']:.4f}\")\n",
    "        print(\"\\nMost common error positions:\")\n",
    "        sorted_errors = sorted(bit_error_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        for bit, count in sorted_errors[:5]:\n",
    "            print(f\"Bit {bit}: {count} errors\")\n",
    "\n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset(data_path: str) -> Dict[str, Any]:\n",
    "    \"\"\"Analyze the dataset to determine appropriate parameters\"\"\"\n",
    "    with open(data_path, \"r\") as f:\n",
    "        data = json.load(f)[\"plans\"]\n",
    "\n",
    "    # Get key statistics\n",
    "    max_plan_length = max(len(item[\"plan\"]) for item in data)\n",
    "    avg_plan_length = sum(len(item[\"plan\"]) for item in data) / len(data)\n",
    "    state_dim = len(data[0][\"initial_state\"])\n",
    "    num_samples = len(data)\n",
    "\n",
    "    stats = {\n",
    "        \"max_plan_length\": max_plan_length,\n",
    "        \"avg_plan_length\": avg_plan_length,\n",
    "        \"state_dim\": state_dim,\n",
    "        \"num_samples\": num_samples,\n",
    "        \"recommended_prediction_length\": max_plan_length + 2,  # Add small buffer\n",
    "    }\n",
    "\n",
    "    print(\"\\nDataset Statistics:\")\n",
    "    print(f\"Number of samples: {num_samples}\")\n",
    "    print(f\"State dimension: {state_dim}\")\n",
    "    print(f\"Maximum plan length: {max_plan_length}\")\n",
    "    print(f\"Average plan length: {avg_plan_length:.2f}\")\n",
    "    print(f\"Recommended prediction length: {stats['recommended_prediction_length']}\")\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of blocks in the dataset: 4\n",
      "\n",
      "Dataset Statistics:\n",
      "Number of samples: 1170\n",
      "State dimension: 24\n",
      "Maximum plan length: 13\n",
      "Average plan length: 6.74\n",
      "Recommended prediction length: 15\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "dataset_file = \"../data/dataset_4.json\"\n",
    "print(f\"Number of blocks in the dataset: {(num_blocks := int(dataset_file.split('_')[-1][0]))}\")\n",
    "\n",
    "# Analyze dataset\n",
    "stats = analyze_dataset(dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 819, Val size: 175, Test size: 176\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = prepare_datasets(\n",
    "    dataset_file,\n",
    "    context_length=CONTEXT_LENGTH,\n",
    "    prediction_length=stats[\"recommended_prediction_length\"],\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}, Test size: {len(test_dataset)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:p-41987:t-8430149376:get_model.py:get_model:Loading model from: ibm-granite/granite-timeseries-ttm-r2\n",
      "WARNING:p-41987:t-8430149376:get_model.py:get_model:Requested `prediction_length` (15) is not exactly equal to any of the available TTM prediction lengths. Hence, TTM will forecast using the `prediction_filter_length` argument to provide the requested prediction length. Check the model card to know more about the supported context lengths and forecast/prediction lengths.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:p-41987:t-8430149376:get_model.py:get_model:Model loaded successfully from ibm-granite/granite-timeseries-ttm-r2, revision = 360-60-ft-l1-r2.1.\n",
      "INFO:p-41987:t-8430149376:get_model.py:get_model:[TTM] context_length = 360, prediction_length = 60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='728' max='1040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 728/1040 13:55 < 05:58, 0.87 it/s, Epoch 14/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TrackingCallback] Mean Epoch Time = 56.357141852378845 seconds, Total Train Time = 838.2185382843018\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train model\n",
    "ttm = BlocksWorldTTM(\n",
    "    context_length=CONTEXT_LENGTH,\n",
    "    prediction_length=stats[\"recommended_prediction_length\"],\n",
    "    learning_rate=1e-4,\n",
    "    batch_size=16,\n",
    "    num_epochs=20,\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "ttm.train(train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../models/blocks_world_ttm_4\n",
      "Saved to ../models/blocks_world_ttm_4\n"
     ]
    }
   ],
   "source": [
    "# Save & Load Model\n",
    "save_path = f\"../models/blocks_world_ttm_{num_blocks}\"\n",
    "\n",
    "ttm.save(save_path)\n",
    "print(f\"Saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:p-41987:t-8430149376:get_model.py:get_model:Loading model from: ibm-granite/granite-timeseries-ttm-r2\n",
      "WARNING:p-41987:t-8430149376:get_model.py:get_model:Requested `prediction_length` (15) is not exactly equal to any of the available TTM prediction lengths. Hence, TTM will forecast using the `prediction_filter_length` argument to provide the requested prediction length. Check the model card to know more about the supported context lengths and forecast/prediction lengths.\n",
      "INFO:p-41987:t-8430149376:get_model.py:get_model:Model loaded successfully from ibm-granite/granite-timeseries-ttm-r2, revision = 360-60-ft-l1-r2.1.\n",
      "INFO:p-41987:t-8430149376:get_model.py:get_model:[TTM] context_length = 360, prediction_length = 60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ../models/blocks_world_ttm_4\n",
      "Loaded from ../models/blocks_world_ttm_4\n"
     ]
    }
   ],
   "source": [
    "ttm = BlocksWorldTTM.load(save_path)\n",
    "print(f\"Loaded from {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model performance...\n",
      "\n",
      "Detailed Model Evaluation Metrics:\n",
      "--------------------------------------------------\n",
      "Total number of test samples: 176\n",
      "Number of exact goal state matches: 7\n",
      "Exact match rate: 0.0398\n",
      "Number of partial matches (>50% correct): 176\n",
      "Partial match rate: 1.0000\n",
      "Bit-level accuracy: 0.7434\n",
      "\n",
      "Analyzing error patterns...\n",
      "\n",
      "Error Pattern Analysis:\n",
      "--------------------------------------------------\n",
      "Number of successful predictions: 7\n",
      "Number of failed predictions: 169\n",
      "Success rate: 0.0398\n",
      "\n",
      "Most common error positions:\n",
      "Bit 17: 95 errors\n",
      "Bit 19: 94 errors\n",
      "Bit 3: 85 errors\n",
      "Bit 1: 80 errors\n",
      "Bit 16: 80 errors\n",
      "\n",
      "--------------------------------------------------\n",
      "Length of the test dataset: 176\n",
      "\n",
      "Example Successes:\n",
      "\n",
      "Case 1:\n",
      "Initial State: BlockState(clear={'B'}, on_table={'A'}, on={'B': 'D', 'C': 'A', 'D': 'C'}, holding=None)\n",
      "Goal State: BlockState(clear={'B'}, on_table={'A'}, on={'B': 'D', 'C': 'A', 'D': 'C'}, holding=None)\n",
      "Predicted Goal: BlockState(clear={'B'}, on_table={'A'}, on={'B': 'D', 'C': 'A', 'D': 'C'}, holding=None)\n",
      "\n",
      "Case 2:\n",
      "Initial State: BlockState(clear={'D', 'A'}, on_table={'B', 'A'}, on={'C': 'B', 'D': 'C'}, holding=None)\n",
      "Goal State: BlockState(clear={'D', 'A'}, on_table={'B', 'A'}, on={'C': 'B', 'D': 'C'}, holding=None)\n",
      "Predicted Goal: BlockState(clear={'D', 'A'}, on_table={'B', 'A'}, on={'C': 'B', 'D': 'C'}, holding=None)\n",
      "\n",
      "Case 3:\n",
      "Initial State: BlockState(clear={'D'}, on_table={'A'}, on={'B': 'C', 'C': 'B', 'D': 'A'}, holding=None)\n",
      "Goal State: BlockState(clear={'D'}, on_table={'A'}, on={'B': 'C', 'C': 'B', 'D': 'A'}, holding=None)\n",
      "Predicted Goal: BlockState(clear={'D'}, on_table={'A'}, on={'B': 'C', 'C': 'B', 'D': 'A'}, holding=None)\n",
      "\n",
      "Example Failures:\n",
      "\n",
      "Case 1:\n",
      "Initial State: BlockState(clear={'B', 'C'}, on_table={'B', 'A'}, on={'C': 'D', 'D': 'A'}, holding=None)\n",
      "Goal State: BlockState(clear={'B', 'D', 'A'}, on_table={'C', 'D', 'A'}, on={'B': 'C'}, holding=None)\n",
      "Predicted Goal: BlockState(clear={'B', 'C'}, on_table={'B', 'A'}, on={'C': 'D', 'D': 'A'}, holding=None)\n",
      "Target Goal: BlockState(clear={'B', 'D', 'A'}, on_table={'C', 'D', 'A'}, on={'B': 'C'}, holding=None)\n",
      "Number of Errors: 9\n",
      "\n",
      "Case 2:\n",
      "Initial State: BlockState(clear={'B', 'A'}, on_table={'D', 'A'}, on={'B': 'C', 'C': 'D'}, holding=None)\n",
      "Goal State: BlockState(clear={'B'}, on_table={'A'}, on={'B': 'D', 'C': 'A', 'D': 'C'}, holding=None)\n",
      "Predicted Goal: BlockState(clear={'B', 'A'}, on_table={'D', 'A'}, on={'B': 'C', 'C': 'D'}, holding=None)\n",
      "Target Goal: BlockState(clear={'B'}, on_table={'A'}, on={'B': 'D', 'C': 'A', 'D': 'C'}, holding=None)\n",
      "Number of Errors: 7\n",
      "\n",
      "Case 3:\n",
      "Initial State: BlockState(clear={'B', 'D', 'C', 'A'}, on_table={'B', 'D', 'C', 'A'}, on={}, holding=None)\n",
      "Goal State: BlockState(clear={'B', 'C'}, on_table={'D', 'A'}, on={'B': 'A', 'C': 'D'}, holding=None)\n",
      "Predicted Goal: BlockState(clear={'B', 'D', 'C', 'A'}, on_table={'B', 'D', 'C', 'A'}, on={}, holding=None)\n",
      "Target Goal: BlockState(clear={'B', 'C'}, on_table={'D', 'A'}, on={'B': 'A', 'C': 'D'}, holding=None)\n",
      "Number of Errors: 6\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "print(\"\\nEvaluating model performance...\")\n",
    "metrics = evaluate_model(ttm, test_dataset)\n",
    "\n",
    "# Analyze error patterns\n",
    "print(\"\\nAnalyzing error patterns...\")\n",
    "analysis = analyze_error_patterns(ttm, test_dataset)\n",
    "successes, failures = analysis[\"successes\"], analysis[\"failures\"]\n",
    "\n",
    "# Examine the inital states, goal states, and actions\n",
    "gen = BlocksWorldGenerator(num_blocks=num_blocks)\n",
    "\n",
    "print(\"\\n--------------------------------------------------\")\n",
    "print(f\"Length of the test dataset: {len(test_dataset)}\")\n",
    "print(\"\\nExample Successes:\")\n",
    "for i, case in enumerate(successes[:3]):\n",
    "    print(f\"\\nCase {i + 1}:\")\n",
    "    print(f\"Initial State: {gen.decode_vector_to_blocks(case['initial_state'])}\")\n",
    "    print(f\"Goal State: {gen.decode_vector_to_blocks(case['goal_state'])}\")\n",
    "    print(f\"Predicted Goal: {gen.decode_vector_to_blocks(case['predicted_goal'])}\")\n",
    "\n",
    "print(\"\\nExample Failures:\")\n",
    "for i, case in enumerate(failures[:3]):\n",
    "    print(f\"\\nCase {i + 1}:\")\n",
    "    print(f\"Initial State: {gen.decode_vector_to_blocks(case['initial_state'])}\")\n",
    "    print(f\"Goal State: {gen.decode_vector_to_blocks(case['goal_state'])}\")\n",
    "    print(f\"Predicted Goal: {gen.decode_vector_to_blocks(case['predicted_goal'])}\")\n",
    "    print(f\"Target Goal: {gen.decode_vector_to_blocks(case['target_goal'])}\")\n",
    "    print(f\"Number of Errors: {case['num_errors']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
