## Dataset

The dataset for PaTS consists of solved planning problem instances from the Blocksworld domain. Each instance includes the problem definition, the expert plan, and the full state trajectory from the initial state to the goal state.

### Generation Workflow

The dataset generation process is designed for efficiency and scalability. It follows a multi-stage workflow that separates expensive, encoding-agnostic computations from the lightweight, encoding-specific processing. This ensures that PDDL generation, planning, and validation are performed only **once** per problem, even when generating data for multiple state encodings.

The `data/generate_dataset_bw.sh` (Blocksworld) and `data/generate_dataset_gr.sh` (Grippers) scripts automate this entire pipeline:

1.  **Stage 1: Encoding-Agnostic Generation (The Heavy Lifting)** This initial stage performs computationally intensive tasks that are independent of the final numerical state encoding.

    - **Problem Generation**: Creates PDDL problem files (`.pddl`) using a domain-specific generator. Here we call to the [pddl-generators](https://github.com/AI-Planning/pddl-generators/tree/main) repository.
    - **Plan Generation**: Uses the [Fast Downward planner](https://github.com/aibasel/downward) to find an optimal solution (`.plan`) for each problem. Problems that cannot be solved within the time limit are discarded.
    - **Plan Validation**: Uses [VAL](https://github.com/KCL-Planning/VAL) to validate the generated plan and produce a verbose log of all state changes (`.val.log`). Invalid plans result in the problem being discarded.

2.  **Stage 2: State Trajectory Extraction (Text Format)**

    - The `data/parse_and_encode.py` script is invoked to process the verbose VAL log (`.val.log`) and reconstruct the full sequence of states from the initial state to the goal state. This sequence is saved in a human-readable text format (`.traj.txt`). This text-based trajectory serves as a canonical, encoding-agnostic representation for a given problem.

3.  **Stage 3: Uniqueness Filtering**

    - To prevent data leakage between training and test sets, a unique hash is generated for each (initial state, goal state) pair. If a newly generated problem is a duplicate of one already processed, it is discarded.

4.  **Stage 4: Multi-Encoding Processing (Numerical Conversion)**

    - The script then **loops through all desired encoding types** (e.g., `bin`, `sas`).

    - For each encoding, `data/parse_and_encode.py` is called _again_. This time, it reads the intermediate text trajectory (`.traj.txt`) and converts it into the specified numerical vector format, saving the results as NumPy arrays (`.npy`). This step is computationally inexpensive as it only involves data transformation.

5.  **Stage 5: Dataset Splitting**
    - Finally, `data/analyze_dataset_splits.py` analyzes the distribution of plan lengths across all successfully generated unique problems. It then creates stratified `train_files.txt`, `val_files.txt`, and `test_files.txt`, ensuring that all instances of a unique (initial, goal) pair are kept within the same split.
    - This script also determines and saves the `max_plan_length.txt` file, which is used by the `pats.sh` script to set the maximum plan generation length for models during benchmarking.

### Data Structure and Format

The dataset is organized into two distinct top-level directories: `raw_problems` for encoding-agnostic source files and `processed_trajectories` for the final numerical data.

#### `data/raw_problems/<domain_name>/<problem_config_name>/`

This directory contains all the raw, **encoding-agnostic** data. It serves as the foundation for all subsequent encoding steps.

- `pddl/`: PDDL problem definition files (`.pddl`).
- `plans/`: Plan files generated by Fast Downward (`.plan`).
- `val_out/`: Verbose output from VAL (`.val.log`).
- `trajectories_text/`: Human-readable text representation of state trajectories (`.traj.txt`). This is the intermediate representation used for all encodings.
- `splits/`: Contains the data splits and analysis artifacts.
  - `train_files.txt`, `val_files.txt`, `test_files.txt`: Lists of problem basenames for each data split.
  - `plan_length_distribution_*.png`: Plots visualizing the plan length distributions.
  - `max_plan_length.txt`: A single integer indicating the maximum plan length found in the dataset for this `num_blocks`.

#### `data/processed_trajectories/<domain_name>/<problem_config_name>/<encoding_type>/`

This directory contains the final, **encoding-specific** numerical representations of state trajectories and their associated metadata. Each encoding type (`bin`, `sas`, etc.) gets its own subdirectory.

- `encoding_info.json`: **Crucial file** describing the encoding used (type, feature dimension, block order, etc.). This file makes each processed dataset self-describing.
- `predicate_manifest.txt`: For `bin` encoding only, this lists all predicates in order, defining the feature map.
- `blocks_<N>_problem_<M>.traj.<encoding>.npy`: NumPy array of shape `(L, F)` containing the encoded state trajectory, where `L` is the number of states in the trajectory (plan length + 1) and `F` is the feature dimension.
- `blocks_<N>_problem_<M>.goal.<encoding>.npy`: NumPy array of shape `(F,)` representing the encoded goal state.

### State Encoding

PaTS supports multiple state encoding schemes, controlled by the `--encoding_type` flag in `parse_and_encode.py`.

#### Binary Predicate Encoding (`bin`)

- **Representation**: A sparse binary vector where each element (bit) corresponds to a unique ground predicate (e.g., `(on-table b1)`). A value of `1` indicates the predicate is true in that state, and `0` indicates it is false.
- **Size**: The dimensionality of this vector scales quadratically with the number of blocks, O(NÂ²). For `N` blocks, the number of possible predicates is approximately `N_on_table + N_on_block + N_clear + N_holding + N_arm_empty = N + N*(N-1) + N + N + 1 = N^2 + 2N + 1`.
- **Example (N=2, simplified)**:
  - Predicates: `(on-table b1)`, `(on-table b2)`, `(on b1 b2)`, `(on b2 b1)`, `(clear b1)`, `(clear b2)`, `(arm-empty)`, `(holding b1)`, `(holding b2)`
  - State "b1 on table, b2 on b1, b2 clear, arm empty": `[1, 0, 0, 1, 0, 1, 1, 0, 0]`
- **Configuration**: The exact order and list of predicates are defined in `predicate_manifest.txt` within the `.../bin/` directory. The `encoding_info.json` file specifies the encoding type as `bin` and references this manifest.

#### SAS+-like Position Vector Encoding (`sas`)

- **Representation**: A dense integer vector where the _index_ represents a block and the _value_ represents its position. This is a multi-valued representation inspired by SAS+ formalisms.
  - `vector[i]` corresponds to block `b(i+1)`.
  - Value `0`: The block is on the table.
  - Value `j > 0`: The block is on top of block `b(j)`.
  - Value `-1`: The block is being held by the arm.
- **Example (N=4)**: For the state "b1 on b2, b2 on table, b3 on b4, b4 on table, arm-empty", the encoding is `[2, 0, 4, 0]`.
- **Size**: Scales linearly with the number of blocks, O(n).
- **Configuration**: The `encoding_info.json` file, located in the `.../sas/` directory, specifies the type as `sas` and lists the canonical block order used for indexing. No separate manifest file is needed.

#### Grippers SAS+ Encoding (`sas`)

- **Representation**: A dense integer vector of size `num_robots + num_objects`.
  - **Robot Positions**: The first `num_robots` elements represent the robots. `vector[i]` stores the room number (e.g., `1` for `room1`) where `robot(i+1)` is located.
  - **Object Positions**: The remaining `num_objects` elements represent the objects.
    - `vector[num_robots + j] = k > 0`: Object `ball(j+1)` is in room `k`.
    - `vector[num_robots + j] = v < 0`: Object `ball(j+1)` is held by a gripper, where `v` is a unique negative ID corresponding to a specific gripper (e.g., `-1` for `robot1`'s left gripper).
- **Example (2 robots, 3 objects)**: For the state "robot1 in room2, robot2 in room1, ball1 in room1, ball2 held by robot1's right gripper (ID -2), ball3 in room2", the encoding could be `[2, 1, 1, -2, 2]`.
- **Size**: Scales linearly with `num_robots + num_objects`.

## Note on SAS+ Goal Vector Generation Strategy

This section explains the difference in how the final goal vector is generated for the SAS+ (`sas`) encoding between the **Blocksworld** and **Grippers** domains.

The core issue stems from the nature of the goal definitions in their respective PDDL files and the requirement of the SAS+ encoding to represent a **complete world state**.

### Blocksworld (`parse_and_encode_bw.py`)

- **Goal Definition**: In the Blocksworld domain, a PDDL goal is typically a **complete specification** of the final state. It defines the final position of every single block (e.g., `(on b1 b2)`, `(on b2 b3)`, `(on-table b3)`).
- **Vector Generation**: Because the PDDL goal contains all the necessary information, the script can directly parse these goal predicates and convert them into a complete SAS+ vector. No information is missing.
- **Conclusion**: The implementation in `parse_and_encode_bw.py` is correct and requires no changes.

### Grippers (`parse_and_encode_gr.py`)

- **Goal Definition**: In the Grippers domain, a PDDL goal is a **partial specification** of the final state. It typically only defines the desired final locations of the objects (e.g., `(at ball1 room2)`), but it does _not_ specify the final locations of the robots.
- **Vector Generation Problem**: This partial goal is insufficient for creating a complete SAS+ state vector, which requires a known location for every robot and object. Attempting to encode this partial goal directly resulted in an error because the robots' positions were undefined.
- **Solution**: The correct goal for the time-series model is the **final state of the expert-generated plan trajectory**. This final state is, by definition, a complete world state that satisfies the partial PDDL goal. The script was therefore modified to use the last vector from the generated state trajectory (`trajectory_np[-1]`) as the true goal vector for the `sas` encoding.

This distinction is why the goal generation logic differs between the two parsing scripts.
